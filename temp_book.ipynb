{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FINAL MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Data prep*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('data/KingSchool.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoricals = ['District']\n",
    "dummies = pd.get_dummies(df2[categoricals], prefix=categoricals, drop_first=True)\n",
    "Kings_preprocessed = df2.drop(categoricals, axis=1)\n",
    "Kings_preprocessed = pd.concat([Kings_preprocessed, dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Kings_preprocessed.drop(['date'],axis=1,inplace=True)\n",
    "Kings_preprocessed = Kings_preprocessed.astype(np.float64)\n",
    "Kings_preprocessed['District_FEDERAL_WAY'] = Kings_preprocessed['District_FEDERAL WAY']\n",
    "Kings_preprocessed['District_LAKE_WASHINGTON'] = Kings_preprocessed['District_LAKE WASHINGTON']\n",
    "Kings_preprocessed['District_MERCER_ISLAND'] = Kings_preprocessed['District_MERCER ISLAND']\n",
    "Kings_preprocessed['District_SNOQUALMIE_VALLEY'] = Kings_preprocessed['District_SNOQUALMIE VALLEY']\n",
    "Kings_preprocessed['District_VASHON_ISLAND'] = Kings_preprocessed['District_VASHON ISLAND']\n",
    "Kings_preprocessed.drop(['District_FEDERAL WAY','District_LAKE WASHINGTON','District_MERCER ISLAND',\n",
    "                         'District_SNOQUALMIE VALLEY','District_VASHON ISLAND'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "King_District_Dummies = ['District_BELLEVUE','District_ENUMCLAW','District_FEDERAL_WAY','District_HIGHLINE',\n",
    "                         'District_ISSAQUAH','District_KENT','District_LAKE_WASHINGTON','District_MERCER_ISLAND',\n",
    "                         'District_NORTHSHORE','District_RENTON','District_RIVERVIEW','District_SEATTLE',\n",
    "                         'District_SHORELINE','District_SKYKOMISH','District_SNOQUALMIE_VALLEY','District_TAHOMA',\n",
    "                         'District_TUKWILA','District_VASHON_ISLAND']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Kings_preprocessed.drop(['id','bedrooms','bathrooms','sqft_lot','floors','waterfront',\n",
    "                         'view','condition','sqft_above','sqft_basement', 'yr_renovated',\n",
    "                         'zipcode','lat','long','sqft_living15','sqft_lot15','renovated_less_10yrs',\n",
    "                         'has_basement','Distance_to_School_ft','mean_price'], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_y = Kings_preprocessed[\"price\"]\n",
    "final_X = Kings_preprocessed.drop(\"price\", axis=1)\n",
    "final_formula = ['sqft_living', 'grade', 'yr_built', 'District_BELLEVUE','District_ENUMCLAW','District_FEDERAL_WAY',\n",
    "                 'District_HIGHLINE','District_ISSAQUAH','District_KENT','District_LAKE_WASHINGTON','District_MERCER_ISLAND',\n",
    "                 'District_NORTHSHORE','District_RENTON','District_RIVERVIEW','District_SEATTLE','District_SHORELINE',\n",
    "                 'District_SKYKOMISH','District_SNOQUALMIE_VALLEY','District_TAHOMA','District_TUKWILA',\n",
    "                 'District_VASHON_ISLAND']\n",
    "final_X = final_X[final_formula]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_X_train, final_X_test, final_y_train, final_y_test = train_test_split(final_X, final_y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "final_X_train_scaled = scaler.fit_transform(final_X_train)\n",
    "final_X_test_scaled = scaler.fit_transform(final_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = LinearRegression()\n",
    "final_model.fit(final_X_train_scaled, final_y_train)\n",
    "final_model.score(final_X_test_scaled, final_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Train RMSE: {mean_squared_error(final_y_train, final_model.predict(final_X_train_scaled), squared=False)}')\n",
    "print(f'Test RMSE: {mean_squared_error(final_y_test, final_model.predict(final_X_test_scaled), squared=False)}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.OLS(final_y_train, sm.add_constant(final_X_train)).fit().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_X_train_scaled = pd.DataFrame(final_X_train_scaled)\n",
    "final_X_train_scaled.columns = final_X.columns\n",
    "final_X_test_scaled = pd.DataFrame(final_X_test_scaled)\n",
    "final_X_test_scaled.columns = final_X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assumptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linearity\n",
    "linearity_plot(final_X_train, final_y_train)\n",
    "#Dummy variables meet the assumption of linearity by definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NORMALITY\n",
    "final_X_test_scaled = pd.DataFrame(final_X_test_scaled)\n",
    "preds_final = final_model.predict(final_X_test_scaled)\n",
    "residuals = (final_y_test - preds_final)\n",
    "sm.graphics.qqplot(residuals, dist=stats.norm, line='45', fit=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking MULTICOLLINEARITY \n",
    "# (VIF NEEDS TO BE <5 ALL CATEGORIES)\n",
    "vif = [variance_inflation_factor(final_X_train_scaled.values, i) for i in range(final_X_train_scaled.shape[1])]\n",
    "pd.Series(vif, index=final_X_train_scaled.columns, name=\"Variance Inflation Factor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_hat_train = final_model.predict(final_X_train_scaled)\n",
    "y_hat_test = preds_final\n",
    "\n",
    "sm.graphics.qqplot(final_y_train-y_hat_train,line='r')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
